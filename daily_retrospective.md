# Ageis Agent 개발 회고록 (Phase 1 ~ 5)

> **작성일:** 2026-02-18
> **작성자:** Ageis 개발팀 (with Claude)
> **주제:** 뼈대부터 얼굴까지, 에이전트의 진화 과정

---

## 1. 서론: 에이전트의 탄생
오늘 우리는 단순한 스크립트가 아닌, **살아있는 소프트웨어 생명체**를 만든다는 목표로 Ageis 프로젝트를 시작했습니다.
Rust의 강력한 보안성과 Python의 유연한 지능을 결합하고, 최종적으로는 사용자가 편하게 쓸 수 있는 데스크톱 앱으로 완성해냈습니다.

이 문서는 `progress.md` 시리즈(1~5)를 바탕으로 우리의 여정을 기록한 회고록입니다.

---

## 2. Phase 별 개발 여정

### Phase 1: 튼튼한 뼈대 (The Body)
> *"보안 없는 지능은 위험하다."*

에이전트가 파일 시스템을 마음대로 헤집고 다니지 못하도록, **Rust 기반의 보안 샌드박스**를 가장 먼저 구축했습니다.
- **성과:** `agent.proto`로 명확한 통신 규약을 정의하고, gRPC로 Rust(서버)와 Python(클라이언트)을 연결했습니다.
- **교훈:** 이종 언어 간의 통신은 초기에 엄격한 타입을 정의하는 것이 유지보수에 훨씬 유리함을 확인했습니다.

### Phase 2: 깨어난 지능 (The Brain)
> *"스스로 생각하고 행동하라."*

단순 명령 수행기가 아닌, 스스로 판단하는 에이전트를 만들기 위해 **ReAct(Reason-Act) 루프**를 구현했습니다.
- **성과:** 사용자의 의도(CHAT/FILE/WEB)를 파악하는 Router를 만들고, 부족한 정보는 스스로 도구를 써서 찾아오는 루프를 완성했습니다.
- **기술:** Ollama(Llama 3.2)를 로컬에 연동하여 비용 없는 지능을 확보했습니다.

### Phase 3: 자아 형성 (The Soul)
> *"기억하지 못하면 성장할 수 없다."*

대화가 끊기면 모든 것을 잊어버리는 금붕어 같은 에이전트에게 **장기 기억(Memory)** 과 **인격(Persona)** 을 부여했습니다.
- **성과:** ChromaDB를 이용한 RAG(검색 증강 생성)로 과거의 대화와 태스크 결과를 영구적으로 기억하게 했습니다. `Aria`라는 전문적인 페르소나도 정의했습니다.
- **변화:** 이제 에이전트는 "지난번에 내가 뭐 했지?"라는 질문에 답할 수 있게 되었습니다.

### Phase 4: 확장과 소통 (Expansion & UX)
> *"쓰기 편해야 좋은 도구다."*

개발자만 쓰는 도구가 되지 않도록, **다양한 인터페이스**와 **플러그인 시스템**을 추가했습니다.
- **성과:**
    - **Plugin System:** 코드 수정 없이 `.py` 파일 추가만으로 기능을 확장하는 구조를 만들었습니다.
    - **CLI Dashboard:** `rich` 라이브러리로 터미널에서도 아름다운 UI를 제공했습니다.
    - **Web UI:** FastAPI와 WebSocket으로 브라우저에서도 대화할 수 있게 되었습니다.

### Phase 5: 얼굴 만들기 (The Face: Tauri Integration)
> *"진정한 앱으로의 도약."*

마지막으로, 이 모든 것을 하나로 포장하여 **설치 가능한 데스크톱 애플리케이션**으로 만들었습니다.
- **성과:** Rust Tauri 프레임워크를 사용해 Python 에이전트를 **Sidecar**로 내장했습니다.
- **결과:** 사용자는 복잡한 터미널 명령어 대신, 아이콘 클릭 한 번으로 Ageis를 만날 수 있습니다. `pyinstaller`로 패키징된 에이전트는 사용자의 PC 환경에 구애받지 않고 동작합니다.

---

## 3. 종합 회고 및 교훈

### 기술적 도전과 극복
1.  **Rust-Python 통합:** 서로 다른 두 언어의 라이프사이클을 관리하는 것이 까다로웠으나, gRPC와 Tauri Sidecar 패턴으로 깔끔하게 해결했습니다.
2.  **Tauri v2 호환성:** 문서와 실제 설정이 다른 부분(`externalBin` 위치 등)이 있었으나, 시행착오 끝에 올바른 설정을 찾아냈습니다.
3.  **로컬 AI의 가능성:** 클라우드 API 없이도, 로컬 LLM(Ollama)만으로 충분히 복잡한 추론과 도구 사용이 가능함을 입증했습니다.


